{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                        @@ Questionary?\n",
    "\n",
    "@ How an automated car will work?\n",
    "\n",
    "        - Maps,GPS,Cameras,Sensors, Algorithms(Need to drive)\n",
    "        \n",
    "        \n",
    "        - Just tell me how you learned Driving ?\n",
    "\n",
    "@ Problem   ->  Solution\n",
    "\n",
    "    - Understand backgroubnd of problem\n",
    "    \n",
    "    - you need to collect its past information/Data\n",
    "    \n",
    "    - You need to identify it's characteristics/behaviour\n",
    "    \n",
    "    - Then you can reproduce the system which is you are looking with the required specifications.\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                @@ Parametric and NonParametric\n",
    "                                \n",
    "                                \n",
    "                                \n",
    "Perametric ML's : -  These are simplify the mapping to known functional form.\n",
    "\n",
    "non-perametric ML's : - These can learn simply from inputs and outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                @@ Different types of equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@ Perametric ML's :-\n",
    "\n",
    "    EX : - \n",
    "    \n",
    "        i/p   o/p   \n",
    "      ------------  \n",
    "        1      4\n",
    "        \n",
    "        2      7\n",
    "        \n",
    "        3      12\n",
    "        \n",
    "        4      19\n",
    "        \n",
    "        5      28\n",
    "        \n",
    "        6       ? Ans : 39\n",
    "        \n",
    "        7       ? Ans : 52\n",
    "        \n",
    "        \n",
    "        \n",
    "        Equation::  Out put  = X ^ 2  + 3\n",
    "        \n",
    "        \n",
    "    Ex: Forcasting the next visit to hospital  {10,20,30,40,more}\n",
    "    \n",
    "                                                                                          dependent\n",
    "    input features/ independent features                                               Target-feature\n",
    "    \n",
    "  S.no  age   gender    employment   eating habits   drinking habits   m1 m2 m3 m4 m5      Next visit\n",
    "    \n",
    "    1\n",
    "    2\n",
    "    3\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    100,000 - records they provided -> they give the next visit also from last visit.\n",
    "    \n",
    "    Which feature is importent ( domain konledge /guidence) / statistical significances\n",
    "    \n",
    "    relationship between ip features and Target feature.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    Result Of your algo is :\n",
    "    \n",
    "    \n",
    "    A * Age + B * Gender + C * Emplo + D * Eating  +E * DH + F........ = 10/20/30/40/more\n",
    "    \n",
    "    \n",
    "    x1   x2  x3   op\n",
    "    -----------------\n",
    "    \n",
    "    1    2   3    14\n",
    "    \n",
    "    1    1   1     6\n",
    "    \n",
    "    1    2   5    19\n",
    "    \n",
    "    1    0   2     7\n",
    "    \n",
    "    2    2   2     13\n",
    "    \n",
    "    3    1   1     ANS : 8\n",
    "    \n",
    "    4    2   0     ANS : 8\n",
    "    \n",
    "    \n",
    "    \n",
    "    A * X1 + B* X2 + C* X3 = output\n",
    "    \n",
    "    1* X1  + 2 * X2 + 3 * X3 = o/p\n",
    "    \n",
    "   \n",
    "\n",
    "   ..\n",
    "    ax + by + c = 0 \n",
    "    \n",
    "    a, b are coefficients of x and y \n",
    "    \n",
    "    \n",
    "    \n",
    "@ Note : Perametric and non-perametric ML's difference ? \n",
    "\n",
    "        \n",
    "            A learning model that summarizes data with a set of peramaeters of fixed size(independent of the number of training examples) is called perametric model. No matter how much data you throw at perametric model, it won't change it's mind about how many perameters needs.\n",
    "            \n",
    "            1. The function\n",
    "            \n",
    "            2. Learning the coefficients from the training data\n",
    "            \n",
    "            \n",
    "                        -> Logistic regression\n",
    "                        -> Linear Discreminant Analysis(LDA)\n",
    "                        -> Perceptron\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "           Pros: \n",
    "           \n",
    "               Speed :  These are very fast to learn from teh data\n",
    "               \n",
    "               Simpler : Easy to understand and interpret results.\n",
    "               \n",
    "               Less Data : Theydo not require as much trianing data , for small also it will fit.\n",
    "               \n",
    "               \n",
    "               \n",
    "            Limitations : \n",
    "            \n",
    "            \n",
    "                Constrained : limited to choose function of specified form.\n",
    "                \n",
    "                limited complexity: This method will be suitable for very simple problems.\n",
    "                \n",
    "                Poor fit : It does not identify all the relation in a proper way . doesn,t map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@ Non Perametric ML'S:\n",
    "\n",
    "    Algorithms do not make any strong assumptions about the form of the mapping function. In this no assumptions, and are free to learn any functional form from the data.\n",
    "    \n",
    "    \n",
    "    Non-Perametric models are very good, if you lot of data, no Preior Knowledge, you dont know about which features you need to select.\n",
    "    \n",
    "    \n",
    "    \n",
    "    Np Methods seek to best fit the training data in constructing the mapping function, it has some ability to generalize to unseen data.\n",
    "    \n",
    "    \n",
    "    \n",
    "        ML\"S : \n",
    "        \n",
    "            - Decission Trees like CART\n",
    "            \n",
    "            - Naive Bayes\n",
    "            \n",
    "            - Support vector Machines\n",
    "            \n",
    "            - Neural Networks\n",
    "            \n",
    "            \n",
    "            \n",
    "       Benfits: \n",
    "       \n",
    "           Flexibility:  Capabile of fitting a large number of functional forms.\n",
    "           \n",
    "           Power:  No assumptions(week assumptions) about the underlaying function.\n",
    "           \n",
    "           Performance : high performance models for predictions\n",
    "           \n",
    "           \n",
    "       Limitations: \n",
    "       \n",
    "       \n",
    "           More data: Require lot more training data to estimate the mapping function.\n",
    "           \n",
    "           Slower : A lot slower to train as they often have more perameters to trian.\n",
    "           \n",
    "           Overfitting : More of a risk to overfit the training data and it is harder to explain why a specific predictions are made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                          70 : 30\n",
    "                Data (Training/ Validating )- {ML-MODEL} -\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@  Supervised  //  Un-supervised // Semi supervised\n",
    "\n",
    "\n",
    "    -> Difference between supervised, un supervised and semi supervised learning algo's.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                @ Supervised machine Learning:\n",
    "\n",
    "\n",
    "\n",
    "Sample Data set:\n",
    "\n",
    "    x1    x2   x3    op\n",
    "    ------------------\n",
    "    \n",
    "    5.7    2   3    14\n",
    "    \n",
    "    1.75   1   1    6\n",
    "    \n",
    "    175    2   5    19\n",
    "    \n",
    "    1      0   2      7\n",
    "    \n",
    "    2      2   2     13\n",
    "    \n",
    "    3      1   1     ANS : 8\n",
    "    \n",
    "    4      2   0     ANS : 8\n",
    "    \n",
    "    \n",
    "    \n",
    "    A * X1 + B* X2 + C* X3 = output\n",
    "    \n",
    "    1* X1  + 2 * X2 + 3 * X3 = o/p\n",
    "\n",
    "\n",
    "inputs/ independent features  \n",
    "\n",
    "output/ Dependent features/ target Variable\n",
    "\n",
    "Each and Every Row is a   -> Observation/ Record -> It belongs to one full action\n",
    "\n",
    "Each and Every column is a  -> One feature{}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        SPL is where you have input variables (X) and an Output Variables(Y) and use an algorithm to learn the mapping function from input to the Output.\n",
    "        \n",
    "                    y  = f(X)\n",
    "                    \n",
    "                   Yes/NO  {1/0} /{True/false} --> Classification/ (Binary classification)\n",
    "                   \n",
    "                   ././././ more than 2 categorirs/ classess -->  (Classification /multiple classes)\n",
    "                   \n",
    "                   It may be a continuous value (Price/Profit/ loss/salary)-->  Regression\n",
    "                   \n",
    "           The goal is approximating the mapping function to estimate as possible as accurate in deducing ouputs from  un known inputs.\n",
    "           \n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Prerequisite:\n",
    "\n",
    "@ Number System :  even -odd\n",
    "    \n",
    "                   whole numbers\n",
    "        \n",
    "                   Natural numbers\n",
    "            \n",
    "                   Integers\n",
    "                \n",
    "                   Prime Numbers\n",
    "                \n",
    "                   rational numbers\n",
    "                \n",
    "                   irrational numbers\n",
    "                \n",
    "                   complex numbers\n",
    "                    \n",
    "                   real numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@ Classification: \n",
    "\n",
    "    When the output variable is categorical  then we will consider that is a classification problem.\n",
    "    \n",
    "    Yes/No  ;  true/ false  :  red/blue/black :  male/ femal : buy/no buy :  young/middle/ old \n",
    "    \n",
    "    low/medium /High: Disease/no disease : 1/2/3/4/5 ->ratings \n",
    "    \n",
    "@ Regression : \n",
    "\n",
    "    When the output variable is a real value, \n",
    "    \n",
    "        1,2,3,4,5,........\n",
    "        \n",
    "        1.5,2.5 ,---------\n",
    "        \n",
    "        -12 ,-10,34,\n",
    "        \n",
    "      {Measurment (Price/weight/speed/height/ count)}\n",
    "      \n",
    "      \n",
    "      \n",
    "          -> Linear regression for regression problems\n",
    "          \n",
    "          -> Random Forest Classification/Regression\n",
    "          \n",
    "          -> Support vector machines (SVM) - Classification\n",
    "          \n",
    "  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                    @@ Unsupervised Learning\n",
    "                                    \n",
    "     USL is where you only have inputs(X) and no corresponding output variables. The goal of USL is to model the underlaying structure/ insights/distributions/ patterns in the data in order to learn more about the data.\n",
    "     \n",
    "         -1. Clustering:\n",
    "         \n",
    "             A clustering problem is where you want to discover the inheritent groupings in the data, such as grouping customers by purchasing behaviour.\n",
    "             \n",
    "    \n",
    "    One class is there: Co- Education\n",
    "             \n",
    "    Divided in to two clusters :  Gender (M/F) // (failed/Pass) // like sports // doesn't like sports\n",
    "              \n",
    "    Divide into 3 groups :  Performance in their education/  (Short/Medium/Tall)/ \n",
    "                            \n",
    "                            Under weight/ normal weight/ Over weight\n",
    "             \n",
    "         \n",
    "         -2. Association:\n",
    "         \n",
    "                 An association rule learning problem is where you want to discover rules that describe large portions of your data, such as people that buy Milk they also tend to buy Sugar.\n",
    "                 \n",
    "                 \n",
    "                 \n",
    "                 \n",
    "                 \n",
    "            -> K- Means for clustering\n",
    "            \n",
    "            -> Apriori algorithm for association rule learning.\n",
    "     \n",
    "     \n",
    "                                    \n",
    "                                    \n",
    "                                    \n",
    "                                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                 @ Semi supervised machine Learning\n",
    "                                 \n",
    "                                 \n",
    "       Problems where you have large amount of input data(X) and only some of the data is labeled with (Y).\n",
    "       \n",
    "       \n",
    "       \n",
    "       X1  X2  X3  X4      X5\n",
    "       \n",
    "       1    3   5   7     odd\n",
    "       \n",
    "       2    4   6   8     even\n",
    "       \n",
    "       \n",
    "       1    5    7  9 \n",
    "       \n",
    "       4    6    8  6\n",
    "       \n",
    "       \n",
    "       3    5    7   9\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31-Aug-2019\n",
    "# Bias -Variance Trade-Off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@ Supervised machine learning:\n",
    "\n",
    "input(X)  --> mapping-Function (f)  -> Output(Y)\n",
    "\n",
    " \n",
    "Prediction :  After trainng Ml algorithm, we will pass vallidation/testing data through ML(Knowledged _body_gained from training_data) then it will give the outputs.(Predicted outputs), this process is called prediction.\n",
    "\n",
    "prediction error: The difference between predicted, and actual outputs.\n",
    "\n",
    "\n",
    "Continoues data:\n",
    "\n",
    " \n",
    "Ex : Actual      Predicted   prediction error\n",
    "\n",
    "\n",
    "        2         2            0\n",
    "        \n",
    "        4         3            1\n",
    "        \n",
    "        6         5            1\n",
    "        \n",
    "        7         7            0\n",
    "        \n",
    "        \n",
    "        8         7            1\n",
    "        \n",
    "        9         9            0\n",
    " \n",
    " \n",
    " \n",
    " Categorical data:   (3 classe)\n",
    " \n",
    " A     p     Correct     \n",
    " \n",
    " 1     1       1\n",
    " 2     2       1\n",
    " 3     1       0\n",
    " 2     3       0\n",
    " 3     3       1\n",
    " 1     2       0\n",
    " 3     3       1\n",
    " 1     1       1\n",
    " 2     2       1\n",
    " 3     3       1\n",
    " 2     2       1 \n",
    " 1     1       1\n",
    " 2     3       0\n",
    " 3     1       0\n",
    " \n",
    " \n",
    " How many types of wrong predictions will possible when 3 classes we have ? \n",
    " \n",
    " Coorect predictions   Wrong predictions\n",
    " \n",
    " 1   --1                1  -- 2 or 3\n",
    " \n",
    " 2   --2                2  -- 1 or 3 \n",
    "  \n",
    " 3   --3                3  -- 1 or 2 \n",
    " \n",
    " \n",
    " The prediction error for any ML algorithm can be divided into 3 parts:\n",
    " \n",
    "         1. Bias Error\n",
    "         2. Variance Error\n",
    "         3. Irreducible Error   \n",
    "         \n",
    "         (normal balence/ electrical weight/ closed box(To increase acuuracy as possible as).\n",
    "         \n",
    "         \n",
    "Note: The irreducible error cannot be reduced regardless of what algorith is used.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@@@ Bias Error:\n",
    "\n",
    "-> Bias are the simplyfying assumptions made by model to make the target function easier to learn.\n",
    "\n",
    "-> Generally parametric algorithms have high bias, and it wil help to making them fast to learn and easier to understand, but with less flexibility.\n",
    "\n",
    "-> They have lower predictrion capacity on complex problems that fial to meet the simplifying assumptions of the algorithms bias.\n",
    "\n",
    "        Low_Bias: Suggests less assumptions about the form of target function(Mapping_Function).\n",
    "        \n",
    "        \n",
    "            EX: Decission Trees\n",
    "            \n",
    "                K - nearest -neighbors\n",
    "                \n",
    "                Support Vector Machines\n",
    "        \n",
    "        High_Bias: Suggests more assumptions about the form of target function.(Mapping function)\n",
    "        \n",
    "        \n",
    "            Ex: Linear Regression\n",
    "                \n",
    "                Logistic Regression\n",
    "                \n",
    "                Linear Discremenent Analysis\n",
    "        \n",
    "        \n",
    "@@ Variance Error:\n",
    "\n",
    "Data -  Data into Traning/Validation {6/4:7/3:8/2}\n",
    "\n",
    "training data  ---->  mapping function\n",
    "\n",
    "What will happen if we choose different trining datasets?\n",
    "\n",
    "\n",
    "t1,t2,t2     ----> Some change should be there in the Mapping function(Target funtion)\n",
    "\n",
    "\n",
    "Based on the above explanation when you will say your model is good ?\n",
    "\n",
    "Ideally it should not change too much from one training dataset to next, meaning that algorithm is good at picking out the hidden patterns underlying mapping between ip and op variables.\n",
    "\n",
    "\n",
    "    Low variance : Suggests small changes to teh target function with changes to the training data.\n",
    "    \n",
    "            Linear regression \n",
    "            \n",
    "            LDA\n",
    "            \n",
    "            Logistic regression\n",
    "    \n",
    "    High variance: Suggests large changes to the target function with changes to the training data.\n",
    "    \n",
    "             EX: Decission Trees\n",
    "            \n",
    "                 K - nearest -neighbors\n",
    "                \n",
    "                 Support Vector Machines\n",
    "    \n",
    "Note:\n",
    "\n",
    "\n",
    "@ Which models will have the high variance ?\n",
    "\n",
    "    Generally non perametric models will have lot of flexibility , because of this in this category high varinace.\n",
    "    \n",
    "@ Ex:  Decission Trees have high varaince, that is even higher if the trees are not pruned before use.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@@@@@@@@@@@@@@@@@@\n",
    "\n",
    "Bias and Varinace  Trade off: \n",
    "\n",
    "\n",
    "                        Bias                  Variance\n",
    " \n",
    "perametric             High                      low\n",
    "\n",
    "non perameric          Low                       High\n",
    "\n",
    "\n",
    "\n",
    "Note :  The goal of any Supervised Ml is to achieve Low Bias and Low variance.\n",
    "\n",
    "\n",
    "1. Parametric or linear ml algos often have high bias and low variance\n",
    "\n",
    "2. non Perametric or non linear algos often have low bias and high varaince.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting and Underfitting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ The cause of poor performance in machine learning is either Overfitting and Underfitting the data.\n",
    "\n",
    "\n",
    "-> OF reffres to learning the trining data too well at the expense of not generalizing well to new data.\n",
    "\n",
    "    Ex: Rote learning....(Batti)\n",
    "    \n",
    "        new Questions are asked? \n",
    "            \n",
    "            no \n",
    "            \n",
    "            What he missied? concept/analysis/knowledge./ understnding-- Generalisation\n",
    "            \n",
    "            \n",
    "-> UF reffers to failing to learn the problem from the training data sufficiently.\n",
    "\n",
    "\n",
    "Note: That overfitting is the most common problem in practice and can be addressed by using resampling methods and a held back verificatino dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@ Generalization in machine learning:\n",
    "\n",
    "    In machine learning we describe the learning of the target function from the training data as inductive learning.\n",
    "    \n",
    "    Inductive reffers to learning general concepts from specific examples which is exactly the problem that sml problems to solve.\n",
    "    \n",
    "    \n",
    "    deduction is learning specific concepts from general rules.\n",
    "    \n",
    "    \n",
    "    Generalization refers to how well the concepts learned by the ml model apply to a specific examples not seen by the model when it was learning.\n",
    "    \n",
    "    \n",
    "    The goal of ml model is generalize well from the training data to any data from the problem domain. this allows us to make predictions in the future on data the model has never seen.\n",
    "    \n",
    "    \n",
    "NOte : OF & UF are the two biggest casues for poor performace of any machine learning model.\n",
    "\n",
    "\n",
    "@@ Statistically fit:  (goodness of fit)\n",
    "      \n",
    "      How well we approximate the target function.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 +3+4 = 9  example specific\n",
    "\n",
    "3 +6 +7 = 16  (Inductive learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "102^2 = ?\n",
    "\n",
    "(a+b)^ 2  = a^2 + b^2 + 2 a b \n",
    "\n",
    "102^2  = (100+2)^ 2 = 100^2 + 2 ^ 2+ 2. 100. 2\n",
    "\n",
    "       = 10000 +4+400\n",
    "    \n",
    "       = 10404   (Deduction learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "good/poor\n",
    "\n",
    "                 Training data         Testing/Validation data\n",
    "    \n",
    "Over fitting       1. Good                  3. Poor\n",
    "\n",
    "Under fitting      2. Poor                  4. Poor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@ Optimization is a very importent part of Machine Learning.\n",
    "\n",
    "@ Every ML algorithm has an optimiziation algorithm at it's core.\n",
    "\n",
    "    @ What is Gradient Descent optimization Algorithm.\n",
    "    \n",
    "    @ How gradient descent can scale to very large datasets?\n",
    "    \n",
    "    @ How we are going to implement in practice.\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Gradient Descent:-\n",
    "\n",
    "        -> GD is an optimization  algorithm used to find the values of coefficients(parameters) of a function {f} that minimizes the cost function.(cost).\n",
    "        \n",
    "        Ex : f = ax +by + cz +gw .......\n",
    "        \n",
    "        \n",
    "        f = it is a generalization about a situation or problem\n",
    "        \n",
    "            a,b,c,g --> coefficients (parameters)\n",
    "            \n",
    "            \n",
    "            What is the meaning of cost function?\n",
    "            \n",
    "                cost function is a function to reduce the errors or mismatches in the algorithm which we are solving . indirectly decreasing error means increasing the performance of the algorithm. this cost function is varied from algorithm to algorithm.\n",
    "                \n",
    "                GD is best used when the parameters cannot be calculated analytically(using linear alzebra) then we must find those with optimization algorithm.\n",
    "                \n",
    "             Example:\n",
    "             \n",
    "                3x +4y +6z = 12\n",
    "                \n",
    "                2x +3y +3z = 14\n",
    "                \n",
    "                \n",
    "                x = ?\n",
    "                y = ?\n",
    "                z = ?\n",
    "                \n",
    "        \n",
    "        Example:\n",
    "         \n",
    "           2x +3y = 9  ---1\n",
    "           \n",
    "           \n",
    "           3x +3y = 6  ---2\n",
    "           \n",
    "           \n",
    "           \n",
    "           X= ?\n",
    "           y =?\n",
    "           \n",
    "           \n",
    "           x + y = 2\n",
    "           \n",
    "           x = 2-y\n",
    "           \n",
    "           2(2-y) +3y = 9\n",
    "           \n",
    "           4-2y+3y = 9\n",
    "           \n",
    "           y = 5\n",
    "           x = -3\n",
    "           \n",
    "           \n",
    "    d/dx (x) = 1 -> slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Intution for gradient descent: -\n",
    "\n",
    "        the bowl is a plot of cost function(f). A random position on the surface of the bowl is the cost of the current values of the coefficients(cost). The bottom  of the bowl is the cost of the best set of coefficients, the minimum of the cost function.\n",
    "        \n",
    "        The goal is to continue to try different values for the coefficients, evaluate their cost and select new coefficients that have slightly better than the previous(cost). repeting  this process enough times will lead to the bottom of the bowl/ or the coefficients of the minimum cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@ Gradient descent procedure :-\n",
    "\n",
    "       \n",
    "       ax +by = c  -- standard function.\n",
    "       \n",
    "       a3 + b3 = 18  --> function\n",
    "       \n",
    "       a, b = coefficients (how to fincd these a,b)\n",
    "       \n",
    "       0.0 X 3 + 0.0 X3 = 0 !=18   <18\n",
    "       \n",
    "       0.1,0.1.........\n",
    "       ................\n",
    "       \n",
    "       \n",
    "       .................\n",
    "       \n",
    "       \n",
    "       3.0 ,3.0 = 18=18\n",
    "       \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@ Batch Gradient Descent : -\n",
    "\n",
    "    Supervised ML : X - > Y\n",
    "    \n",
    "    We need to identify the mapping function x - > y\n",
    "    \n",
    "      data -> optimazation - GD -> ......\n",
    "      \n",
    "    to identify the coefficients of the function ->  cofeeficients -1\n",
    "    \n",
    "    \n",
    "    one iteration of the data - > one Batch -> GD -> Batch GD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@ Stochastic GD : -\n",
    "\n",
    "\n",
    "coefficients update after each and every observation  -> function -> SGD (Varaition in the gradient descent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Learning rate : L =0.1 , 0.1, 0.01, 0.001\n",
    "    \n",
    "Rescale - X(inputs) -> 0 and 1\n",
    "\n",
    "SGD - Data (1-10) - optimized coefficients for cost function.\n",
    "\n",
    "\n",
    "BGD VS SGD:\n",
    "    \n",
    "1,2,3,4,5,6,7,8,9,10  -> data\n",
    "\n",
    "a2 +b3 = 10\n",
    "\n",
    "  data ->  optimization-->  a+1,b +1  -> BGD\n",
    "    \n",
    "    1 -> optimization -> a+0.0001 +b+0.000000001 - > SGD\n",
    "    2 -> optimization -> a+0.0011 +b+0.000021 - > SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@ Sigmoid Function -> What it is  -> Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@ Regression : Target variable is a real value\n",
    "    \n",
    "@ Classification : Target varaible is categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@  Logistic Rgression   -> Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@ chance\n",
    "@ Probability = \n",
    "\n",
    "\n",
    "Example  = Exam   => What are the total possible outputs = {Pass, Fail}\n",
    "\n",
    "\n",
    "to pass exam 50 % chance {to fail also 50 % }\n",
    "\n",
    "\n",
    "what is the chance to pass the exam ? = Pass(1)/(pass+Fail)(2) = 0.5\n",
    "\n",
    "\n",
    "@@@@@ probability  = required condition / Total possible out puts \n",
    "\n",
    "\n",
    "Marks = 30,40,50,60,70,80,90\n",
    "\n",
    "Condition marks =! 30 means he is pass \n",
    "\n",
    "what is the probability of pass for a student who is selected randomly = 6/7\n",
    "\n",
    "\n",
    "what is the maximum probability  = 1.0\n",
    "\n",
    "what is the minimum probability  = 0.0\n",
    "\n",
    "\n",
    "0.0<=praobability <=1.0  General statement\n",
    "\n",
    "\n",
    "Regression : Continoues value:\n",
    "\n",
    "logistic regression:\n",
    "\n",
    "0.2,0.3,0.4,0.45,0.49,0.50,0.51,0.52,0.53,0.54,0.62,0.69,,0.75,0.81,0.91,0.95\n",
    "\n",
    "--> filter -> results as 0 or 1 => (Thresholding) {0.0<= Zero <=0.5, 0.5<One<=1.0}\n",
    "\n",
    "0,0,0,0,0,................1,1,1,1,1,1...........................................\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Classification and Regression Trees: {CART}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@ Decession -> choose one option from avilable\n",
    "\n",
    "@ Tree -> Root, Branches, leaves\n",
    "\n",
    "@ Predective Modeling -> designing future ........\n",
    "\n",
    "\n",
    "@ node : splitting the data\n",
    "\n",
    "Example : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data -> CART -> data need to divide into 2 groups (basis of what condition ? )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@ CART Algorithm  -> Decission Trees , Random Forest, Boosted decission Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@ Binary Tree\n",
    "\n",
    "\n",
    "                                         Height > 180 cm\n",
    "                                         \n",
    "                                     Yes                 No\n",
    "                                     \n",
    "                                     \n",
    "                                     Male             Weight >80 Kg\n",
    "                                     \n",
    "                                     \n",
    "                                                     Yes         No\n",
    "                                                     \n",
    "                                                   Male          Female\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
